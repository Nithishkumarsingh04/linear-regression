{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "\n",
        " It models the relationship between one independent variable (X) and one dependent variable (Y) using a straight line.\n",
        "\n",
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        " Linearity\n",
        "\n",
        " Independence of errors\n",
        "\n",
        " Constant error variance (Homoscedasticity)\n",
        "\n",
        " Normally distributed residuals\n",
        "\n",
        "3. What does the coefficient m represent in the equation Y = mX + c?\n",
        "\n",
        " m is the slope, showing how much Y changes for a one-unit increase in X.\n",
        "\n",
        "4. What does the intercept c represent in the equation Y = mX + c?\n",
        "\n",
        " c is the intercept; it's the predicted value of Y when X = 0.\n",
        "\n",
        "5. How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        " 𝑚\n",
        "=\n",
        "∑\n",
        "(\n",
        "𝑋\n",
        "−\n",
        "𝑋\n",
        "ˉ\n",
        ")\n",
        "(\n",
        "𝑌\n",
        "−\n",
        "𝑌\n",
        "ˉ\n",
        ")\n",
        "∑\n",
        "(\n",
        "𝑋\n",
        "−\n",
        "𝑋\n",
        "ˉ\n",
        ")\n",
        "2\n",
        "m=\n",
        "∑(X−\n",
        "X\n",
        "ˉ\n",
        " )\n",
        "2\n",
        "\n",
        "∑(X−\n",
        "X\n",
        "ˉ\n",
        " )(Y−\n",
        "Y\n",
        "ˉ\n",
        " )\n",
        "​\n",
        "\n",
        "\n",
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        " To minimize the total squared difference between actual and predicted Y values.\n",
        "\n",
        "7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
        "\n",
        " R² shows how much of the variance in Y is explained by X (ranges from 0 to 1).\n",
        "\n",
        "8. What is Multiple Linear Regression?\n",
        "\n",
        " It models the relationship between two or more independent variables and one dependent variable.\n",
        "\n",
        "9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        " Simple has 1 predictor; Multiple has 2 or more predictors.\n",
        "\n",
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        " Linearity\n",
        "\n",
        " Independence\n",
        "\n",
        " Homoscedasticity\n",
        "\n",
        " No multicollinearity\n",
        "\n",
        " Normal residuals\n",
        "\n",
        "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        " It means unequal error variance; it can make standard errors unreliable and affect significance tests.\n",
        "\n",
        "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        " Remove correlated variables\n",
        "\n",
        " Use PCA\n",
        "\n",
        " Apply Ridge or Lasso regression\n",
        "\n",
        "13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        " One-hot encoding\n",
        "\n",
        " Label encoding\n",
        "\n",
        " Binary encoding\n",
        "\n",
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        " They capture the combined effect of two variables on the dependent variable.\n",
        "\n",
        "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        " In simple, it's Y when X = 0. In multiple, it's Y when all predictors = 0, which may not be meaningful.\n",
        "\n",
        "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        " It shows how Y changes with each unit increase in a predictor.\n",
        "\n",
        "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        " It gives the baseline value of Y when all predictors are 0.\n",
        "\n",
        "18. What are the limitations of using R² as a sole measure of model performance?\n",
        "\n",
        " It can be misleading; doesn’t reflect overfitting or model complexity.  \n",
        "\n",
        "19. How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        " It suggests the coefficient estimate is unstable and possibly not significant.\n",
        "\n",
        "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        " In residual plots, look for fan/funnel shapes. Fixing it ensures valid inferences.\n",
        "\n",
        "21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
        "\n",
        " It suggests that extra variables are not improving the model and may be irrelevant.\n",
        "\n",
        "22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        " To ensure equal weight to all predictors and improve model stability and interpretability.\n",
        "\n",
        "23. What is Polynomial Regression?\n",
        "\n",
        " A regression technique that fits a curved relationship using polynomial terms of X.\n",
        "\n",
        "24. How does polynomial regression differ from linear regression?\n",
        "\n",
        " Polynomial regression models non-linear trends; linear regression models straight-line relationships.\n",
        "\n",
        "25. When is polynomial regression used?\n",
        "\n",
        " When the data shows a non-linear trend that linear regression cannot capture.\n",
        "\n",
        "26. What is the general equation for polynomial regression?\n",
        "\n",
        " 𝑌\n",
        "=\n",
        "𝑏\n",
        "0\n",
        " +\n",
        "𝑏\n",
        "1\n",
        "𝑋\n",
        " +\n",
        "𝑏\n",
        "2\n",
        "𝑋\n",
        "2\n",
        " +\n",
        "𝑏\n",
        "3\n",
        "𝑋\n",
        "3\n",
        " +\n",
        "⋯\n",
        " +\n",
        "𝑏\n",
        "𝑛\n",
        "𝑋\n",
        "𝑛\n",
        "Y=b\n",
        "0\n",
        "​\n",
        " +b\n",
        "1\n",
        "​\n",
        " X+b\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        " +b\n",
        "3\n",
        "​\n",
        " X\n",
        "3\n",
        " +⋯+b\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        "\n",
        "\n",
        "27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        " Yes, it's called multiple polynomial regression (e.g., with X, Y, X², XY, etc.).\n",
        "\n",
        "28. What are the limitations of polynomial regression?\n",
        "\n",
        "Overfitting\n",
        "\n",
        " Poor extrapolation\n",
        "\n",
        " Hard to interpret\n",
        "\n",
        " Sensitive to outliers\n",
        "\n",
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        " Adjusted R²\n",
        "\n",
        " Cross-validation\n",
        "\n",
        " AIC/BIC\n",
        "\n",
        " Residual analysis\n",
        "\n",
        "30. Why is visualization important in polynomial regression?\n",
        "\n",
        " It helps assess curve fit, detect overfitting/underfitting, and interpret patterns.\n",
        "\n",
        "31. How is polynomial regression implemented in Python?\n",
        "\n",
        " from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        " from sklearn.linear_model import LinearRegression\n",
        "\n",
        " poly = PolynomialFeatures(degree=2)\n",
        " X_poly = poly.fit_transform(X)\n",
        "\n",
        " model = LinearRegression().fit(X_poly, y)"
      ],
      "metadata": {
        "id": "hJF6DoJGOLr-"
      }
    }
  ]
}